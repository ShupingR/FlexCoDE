% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/basicFunctionsKernel.R
\name{fitFlexCoDEKernel}
\alias{fitFlexCoDEKernel}
\title{FlexCoDE Fit Conditional Density Estimation via Regression}
\usage{
fitFlexCoDEKernel(kernelTrainTrain, zTrain, kernelValidationTrain, zValidation,
  kernelTestTrain = NULL, zTest = NULL, nIMax = min(25, length(zTrain)),
  regressionFunction, regressionFunction.extra = NULL, system = "Fourier",
  deltaGrid = seq(0, 0.4, 0.05), chooseDelta = TRUE, verbose = TRUE)
}
\arguments{
\item{zTrain}{Responses z used to train the model  (matrix with one column; one observation per row)}

\item{zValidation}{Responses z used to tune the model  (matrix with one column; one observation per row)}

\item{zTest}{Responses z used to estimate risk of final model  (matrix with one column; one observation per row). Default is NULL}

\item{nIMax}{Maximum possible number of components of the series expansion (that is, the function will find the best I<nIMax). Default is 100}

\item{regressionFunction}{a function indicating which regression method will be used to estimate the expansion coefficients. Currently can be one of}

\item{regressionFunction.extra}{extra parameters to be sent to regression function; see the regression you want to use to check what are the available parameters}

\item{system}{Basis for z. Current options are "Fourier", "Cosine" and "discrete". Default is "Fourier"}

\item{deltaGrid}{Grid of threshold deltas (betwen 0 and 0.5). Default value is seq(0,0.4,0.05).}

\item{chooseDelta}{Should delta, the cutoff to remove spurious bumps, be chosen?}

\item{verbose}{Should we print what we are doing? Default is TRUE.}

\item{xTrain}{Covariates x used to train the model (one observation per row)}

\item{xValidation}{Covariates x used to tune the model (one observation per row; same number of columns as xTrain)}

\item{xTest}{Covariates x used to estimate risk of final model (one observation per row; same number of columns as xTrain). Default is NULL}
}
\value{
Returns the fitted estimated conditional density, and object of the class FlexCoDE. The return value is an object with the following components:
\item{zMin, zMax}{Minimum and maximum value of z}
\item{nIMax}{Maximum number of expansion coefficients (user input). Default is minimum between 25 and number of training samples.}
\item{system}{Basis used for expanding the response}
\item{zTrain}{zTrain (user input)}
\item{xTrain}{xTrain (user input)}
\item{regressionObject}{Object with fitted regressions. Class and content depend on which regression method was chosen by user}
\item{errors}{Estimated errors for each value of I (number of expansion coefficients) using validation set}
\item{bestI}{Optimal number of I according to validation set}
\item{bestError}{Estimated error of model with bestI expansion terms according to validation set}
\item{bestDelta}{Optimal value of threshold delta according to validation set}
\item{estimatedRisk}{(If user provides xTest and zTest) Estimated risk (error) according to test set)}
}
\description{
FlexCoDE Fit Conditional Density Estimation via Regression
}
\examples{
set.seed(400)

# generate data
n=1000
d=10
data=matrix(NA,n,d+1)
data[,1:d]=matrix(rnorm(n*d),n,d)
data[,d+1]=data[,1]+rnorm(n,0,0.1)

# determine sample sizes
nTrain=round(0.7*n)
nValidation=round(0.25*n)
nTest=n-nTrain-nValidation

# compute kernel
distanceMatrix=fields::rdist(data[,1:d],data[,1:d])

# split data
randomIndex=sample(1:n)
zTrain=data[randomIndex[1:nTrain],d+1]
zValidation=data[randomIndex[(nTrain+1):(nTrain+nValidation)],d+1]
zTest=data[randomIndex[(nTrain+nValidation+1):n],d+1]


############################################################
###### fit NN estimator (not appropriate for sparse structure)
############################################################
kernelTrainTrain=-distanceMatrix[randomIndex[1:nTrain],randomIndex[1:nTrain]]^2
kernelValidationTrain=-distanceMatrix[randomIndex[(nTrain+1):(nTrain+nValidation)],randomIndex[1:nTrain]]^2
fit=fitFlexCoDEKernel(kernelTrainTrain,zTrain,kernelValidationTrain,zValidation,
                      nIMax = 20,regressionFunction = regressionFunction.NNKernel,chooseDelta = FALSE)
kernelTestTrain=-distanceMatrix[randomIndex[(nTrain+nValidation+1):n],randomIndex[1:nTrain]]^2
fit1=fitFlexCoDEKernel(kernelTrainTrain,zTrain,kernelValidationTrain,zValidation,kernelTestTrain,zTest,
                      nIMax = 20,regressionFunction = regressionFunction.NNKernel)
fit1$estimatedRisk


# Plot estimator
plot(fit,kernelTestTrain,zTest)




############################################################
######## Series
############################################################
epsGrid=seq(0.1,10,length.out = 5)
error=rep(NA,length(epsGrid))
for(i in 1:length(epsGrid))
{
  print(i/length(epsGrid))
  kernelTrainTrain=exp(-(distanceMatrix[randomIndex[1:nTrain],randomIndex[1:nTrain]]^2/(4*epsGrid[i])))
  kernelValidationTrain=exp(-(distanceMatrix[randomIndex[(nTrain+1):(nTrain+nValidation)],randomIndex[1:nTrain]]^2/(4*epsGrid[i])))


  fit=fitFlexCoDEKernel(kernelTrainTrain,zTrain,kernelValidationTrain,zValidation,
                        nIMax = 20,regressionFunction = regressionFunction.SeriesKernel,chooseDelta = FALSE)
  error[i]=fit$bestError
}
plot(error)

bestEps=epsGrid[which.min(error)]

kernelTrainTrain=exp(-(distanceMatrix[randomIndex[1:nTrain],randomIndex[1:nTrain]]^2/(4*bestEps)))
kernelValidationTrain=exp(-(distanceMatrix[randomIndex[(nTrain+1):(nTrain+nValidation)],randomIndex[1:nTrain]]^2/(4*bestEps)))
kernelTestTrain=exp(-(distanceMatrix[randomIndex[(nTrain+nValidation+1):n],randomIndex[1:nTrain]]^2/(4*bestEps)))


fit2=fitFlexCoDEKernel(kernelTrainTrain,zTrain,kernelValidationTrain,zValidation,kernelTestTrain,zTest,
                      nIMax = 20,regressionFunction = regressionFunction.SeriesKernel)
fit2$estimatedRisk



############################################################
######## SDM
############################################################
epsGrid=seq(0.1,5,length.out = 5)
error=rep(NA,length(epsGrid))
for(i in 1:length(epsGrid))
{
  print(i/length(epsGrid))
  kernelTrainTrain=exp(-(distanceMatrix[randomIndex[1:nTrain],randomIndex[1:nTrain]]^2/(4*epsGrid[i])))
  kernelValidationTrain=exp(-(distanceMatrix[randomIndex[(nTrain+1):(nTrain+nValidation)],randomIndex[1:nTrain]]^2/(4*epsGrid[i])))


  fit=fitFlexCoDEKernel(kernelTrainTrain,zTrain,kernelValidationTrain,zValidation,
                        nIMax = 20,regressionFunction = regressionFunction.SDMKernel,
                        regressionFunction.extra = list(C=5,eps=0.01),chooseDelta = FALSE)
  error[i]=fit$bestError
}
plot(error)

bestEps=epsGrid[which.min(error)]

kernelTrainTrain=exp(-(distanceMatrix[randomIndex[1:nTrain],randomIndex[1:nTrain]]^2/(4*bestEps)))
kernelValidationTrain=exp(-(distanceMatrix[randomIndex[(nTrain+1):(nTrain+nValidation)],randomIndex[1:nTrain]]^2/(4*bestEps)))
kernelTestTrain=exp(-(distanceMatrix[randomIndex[(nTrain+nValidation+1):n],randomIndex[1:nTrain]]^2/(4*bestEps)))


fit2=fitFlexCoDEKernel(kernelTrainTrain,zTrain,kernelValidationTrain,zValidation,kernelTestTrain,zTest,
                       nIMax = 20,regressionFunction = regressionFunction.SDMKernel,regressionFunction.extra = list(C=5,eps=0.01))
fit2$estimatedRisk
}

